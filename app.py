import streamlit as st
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

try:
    from prophet import Prophet
    PROPHET_AVAILABLE = True
except ImportError:
    PROPHET_AVAILABLE = False
    st.warning("‚ö†Ô∏è Prophet –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ. –ü—Ä–æ–≥–Ω–æ–∑–∏ –±—É–¥—É—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ.")

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from io import BytesIO

st.set_page_config(page_title="–ê–Ω–∞–ª—ñ–∑ —Ç–æ–≤–∞—Ä—ñ–≤", layout="wide")

# –°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è —Å—Ç–∏–ª–∏–∑–∞—Ü–∏—è —Å –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏ –∏ —Ä–∞–º–∫–∞–º–∏
st.markdown("""
<style>
    /* –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Ñ–æ–Ω –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ */
    .stApp {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 25%, #f093fb 50%, #4facfe 75%, #00f2fe 100%);
        background-size: 400% 400%;
        animation: gradientShift 15s ease infinite;
    }

    @keyframes gradientShift {
        0% { background-position: 0% 50%; }
        50% { background-position: 100% 50%; }
        100% { background-position: 0% 50%; }
    }

    /* –°—Ç–∏–ª—å–Ω—ã–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã —Å —Ä–∞–º–∫–∞–º–∏ */
    .stApp > div {
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(10px);
        border-radius: 20px;
        border: 2px solid rgba(255, 255, 255, 0.3);
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
        padding: 20px;
        margin: 10px 0;
    }

    /* –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ h1 */
    h1 {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        font-weight: 800;
        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.1);
        padding: 20px 0;
        border-bottom: 3px solid transparent;
        border-image: linear-gradient(90deg, #667eea, #764ba2, #f093fb);
        border-image-slice: 1;
        margin-bottom: 30px;
    }

    /* –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ h2 */
    h2 {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        font-weight: 700;
        padding: 15px 0;
        border-left: 5px solid #f093fb;
        padding-left: 15px;
        margin: 25px 0 15px 0;
    }

    /* –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ h3 */
    h3 {
        background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        font-weight: 600;
        padding: 10px 0;
        border-left: 4px solid #4facfe;
        padding-left: 12px;
        margin: 20px 0 10px 0;
    }

    /* –°—Ç–∏–ª—å–Ω—ã–µ —Ä–∞–º–∫–∏ –¥–ª—è —Ä–∞–∑–¥–µ–ª–æ–≤ */
    .stMarkdown {
        border-radius: 15px;
        padding: 15px;
        margin: 10px 0;
    }

    /* –†–∞–º–∫–∏ –¥–ª—è –º–µ—Ç—Ä–∏–∫ */
    [data-testid="stMetricValue"] {
        background: linear-gradient(135deg, rgba(102, 126, 234, 0.1) 0%, rgba(118, 75, 162, 0.1) 100%);
        border: 2px solid rgba(102, 126, 234, 0.3);
        border-radius: 12px;
        padding: 10px;
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.05);
    }

    /* –°—Ç–∏–ª—å–Ω—ã–µ –∫–Ω–æ–ø–∫–∏ —Å –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–º */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 12px;
        padding: 12px 30px;
        font-weight: 600;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
        transition: all 0.3s ease;
        border: 2px solid rgba(255, 255, 255, 0.2);
    }

    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6);
        background: linear-gradient(135deg, #764ba2 0%, #667eea 100%);
    }

    /* –†–∞–º–∫–∏ –¥–ª—è –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ */
    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, rgba(102, 126, 234, 0.95) 0%, rgba(118, 75, 162, 0.95) 100%);
        border-right: 3px solid rgba(255, 255, 255, 0.3);
        box-shadow: 4px 0 20px rgba(0, 0, 0, 0.1);
    }

    [data-testid="stSidebar"] * {
        color: white !important;
    }

    /* –†–∞–º–∫–∏ –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤ */
    .stAlert {
        border-radius: 12px;
        border: 2px solid rgba(102, 126, 234, 0.3);
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.05);
    }

    /* –†–∞–º–∫–∏ –¥–ª—è expander */
    .streamlit-expanderHeader {
        background: linear-gradient(135deg, rgba(102, 126, 234, 0.1) 0%, rgba(118, 75, 162, 0.1) 100%);
        border: 2px solid rgba(102, 126, 234, 0.2);
        border-radius: 12px;
        padding: 10px;
        font-weight: 600;
    }

    /* –†–∞–º–∫–∏ –¥–ª—è dataframe */
    .stDataFrame {
        border: 2px solid rgba(102, 126, 234, 0.2);
        border-radius: 12px;
        overflow: hidden;
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.05);
    }

    /* –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å–Ω—ã–µ –ª–∏–Ω–∏–∏ */
    hr {
        border: none;
        height: 3px;
        background: linear-gradient(90deg, #667eea, #764ba2, #f093fb, #4facfe);
        margin: 30px 0;
        border-radius: 2px;
    }

    /* –†–∞–º–∫–∏ –¥–ª—è input –ø–æ–ª–µ–π */
    .stTextInput > div > div > input,
    .stSelectbox > div > div > div,
    .stNumberInput > div > div > input {
        border: 2px solid rgba(102, 126, 234, 0.3);
        border-radius: 10px;
        padding: 10px;
        transition: all 0.3s ease;
    }

    .stTextInput > div > div > input:focus,
    .stSelectbox > div > div > div:focus,
    .stNumberInput > div > div > input:focus {
        border-color: #667eea;
        box-shadow: 0 0 15px rgba(102, 126, 234, 0.3);
    }

    /* –†–∞–º–∫–∏ –¥–ª—è slider */
    .stSlider {
        padding: 15px;
        background: rgba(255, 255, 255, 0.5);
        border-radius: 12px;
        border: 2px solid rgba(102, 126, 234, 0.2);
        margin: 10px 0;
    }

    /* –°—Ç–∏–ª—å–Ω—ã–µ —Ä–∞–∑–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –º–µ–∂–¥—É —Å–µ–∫—Ü–∏—è–º–∏ */
    .stMarkdown + .stMarkdown {
        margin-top: 25px;
        padding-top: 25px;
    }

    /* –†–∞–º–∫–∏ –¥–ª—è radio buttons */
    .stRadio > div {
        background: rgba(255, 255, 255, 0.7);
        border: 2px solid rgba(102, 126, 234, 0.2);
        border-radius: 12px;
        padding: 15px;
    }

    /* –†–∞–º–∫–∏ –¥–ª—è file uploader */
    [data-testid="stFileUploader"] {
        border: 2px dashed rgba(102, 126, 234, 0.4);
        border-radius: 12px;
        padding: 20px;
        background: rgba(255, 255, 255, 0.5);
    }
</style>
""", unsafe_allow_html=True)

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è session_state
if 'run_analysis' not in st.session_state:
    st.session_state.run_analysis = False
if 'loaded_data' not in st.session_state:
    st.session_state.loaded_data = None
if 'data_source_type' not in st.session_state:
    st.session_state.data_source_type = None

st.title("üîç –ê–Ω–∞–ª—ñ–∑ —Ç–æ–≤–∞—Ä—ñ–≤: –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∫–∞–Ω–¥–∏–¥–∞—Ç—ñ–≤ –Ω–∞ –∑–Ω—è—Ç—Ç—è")

# === –ù–ê–õ–ê–®–¢–£–í–ê–ù–ù–Ø ===
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è")
    TOP_N = st.slider("–ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–ø-–∞—Ä—Ç–∏–∫—É–ª—ñ–≤ –¥–ª—è Prophet", 10, 50, 20)

    st.subheader("üéØ –ö—Ä–∏—Ç–µ—Ä—ñ—ó –∑–Ω—è—Ç—Ç—è")
    zero_weeks_threshold = st.slider("–¢–∏–∂–Ω—ñ–≤ –ø—ñ–¥—Ä—è–¥ –±–µ–∑ –ø—Ä–æ–¥–∞–∂—ñ–≤", 8, 20, 12)
    min_total_sales = st.slider("–ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π –æ–±—Å—è–≥ –ø—Ä–æ–¥–∞–∂—ñ–≤", 1, 50, 5)
    max_store_ratio = st.slider("–ú–∞–∫—Å. —á–∞—Å—Ç–∫–∞ –º–∞–≥–∞–∑–∏–Ω—ñ–≤ –±–µ–∑ –ø—Ä–æ–¥–∞–∂—ñ–≤ (%)", 70, 95, 85, 5) / 100

    st.subheader("ü§ñ –ú–æ–¥–µ–ª—å ML")
    use_balanced_model = st.checkbox("–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –±–∞–ª–∞–Ω—Å—É–≤–∞–Ω–Ω—è –∫–ª–∞—Å—ñ–≤", value=True)
    final_threshold = st.slider("–§—ñ–Ω–∞–ª—å–Ω–∏–π –ø–æ—Ä—ñ–≥ –¥–ª—è –∑–Ω—è—Ç—Ç—è (%)", 50, 90, 70, 5) / 100

    st.divider()

    # –ö–Ω–æ–ø–∫–∞ –æ—á–∏—â–µ–Ω–Ω—è –∫–µ—à—É
    if st.button("üîÑ –û—á–∏—Å—Ç–∏—Ç–∏ –∫–µ—à –¥–∞–Ω–∏—Ö"):
        st.session_state.loaded_data = None
        st.cache_data.clear()
        st.success("–ö–µ—à –æ—á–∏—â–µ–Ω–æ!")
        st.rerun()

# === –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –î–ê–ù–ò–• ===
st.header("üìÅ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö")
st.info("üí° –§–æ—Ä–º–∞—Ç: –¥–∞—Ç–∞, –∞—Ä—Ç–∏–∫—É–ª, –∫—ñ–ª—å–∫—ñ—Å—Ç—å, –º–∞–≥–∞–∑–∏–Ω, –Ω–∞–∑–≤–∞")

# –í–∏–±—ñ—Ä –¥–∂–µ—Ä–µ–ª–∞ –¥–∞–Ω–∏—Ö
data_source = st.radio(
    "–û–±–µ—Ä—ñ—Ç—å –¥–∂–µ—Ä–µ–ª–æ –¥–∞–Ω–∏—Ö:",
    ["Google Sheets", "–õ–æ–∫–∞–ª—å–Ω–∏–π —Ñ–∞–π–ª"],
    horizontal=True
)

uploaded_file = None
sheets_url = None

if data_source == "–õ–æ–∫–∞–ª—å–Ω–∏–π —Ñ–∞–π–ª":
    uploaded_file = st.file_uploader("–û–±–µ—Ä—ñ—Ç—å Excel —Ñ–∞–π–ª", type=['xlsx', 'xls'])
else:
    sheets_url = st.text_input(
        "–ü–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ Google Sheets:",
        value="https://docs.google.com/spreadsheets/d/1lJLON5N_EKQ5ICv0Pprp5DamP1tNAhBIph4uEoWC04Q/edit?gid=64159818#gid=64159818",
        help="–¢–∞–±–ª–∏—Ü—è –ø–æ–≤–∏–Ω–Ω–∞ –º–∞—Ç–∏ –ø—É–±–ª—ñ—á–Ω–∏–π –¥–æ—Å—Ç—É–ø"
    )

# === –ö–ï–®–û–í–ê–ù–Ü –§–£–ù–ö–¶–Ü–á –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø ===
@st.cache_data(show_spinner=False)
def _fetch_google_sheets_data(sheets_url):
    """–ö–µ—à–æ–≤–∞–Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Å–∏—Ä–∏—Ö –¥–∞–Ω–∏—Ö –∑ Google Sheets"""
    import re
    import time

    # –í–∏—Ç—è–≥—É—î–º–æ spreadsheet ID
    spreadsheet_match = re.search(r'/spreadsheets/d/([a-zA-Z0-9-_]+)', sheets_url)
    if not spreadsheet_match:
        raise ValueError("–ù–µ–≤—ñ—Ä–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ Google Sheets")

    spreadsheet_id = spreadsheet_match.group(1)

    # –í–∏—Ç—è–≥—É—î–º–æ GID (ID –∞—Ä–∫—É—à–∞)
    gid_match = re.search(r'[#&]gid=([0-9]+)', sheets_url)
    gid = gid_match.group(1) if gid_match else '0'

    # –§–æ—Ä–º—É—î–º–æ URL –¥–ª—è –µ–∫—Å–ø–æ—Ä—Ç—É –≤ Excel —Ñ–æ—Ä–º–∞—Ç—ñ
    export_url = f"https://docs.google.com/spreadsheets/d/{spreadsheet_id}/export?format=xlsx&gid={gid}"

    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–∞–Ω—ñ –∑ –ø—Ä–æ–≥—Ä–µ—Å-–±–∞—Ä–æ–º
    progress_bar = st.progress(0, text="üîÑ –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ Google Sheets...")
    time.sleep(0.3)
    progress_bar.progress(20, text="üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö...")

    df = pd.read_excel(export_url, nrows=100000)

    progress_bar.progress(80, text="‚úÖ –û–±—Ä–æ–±–∫–∞ –¥–∞–Ω–∏—Ö...")
    time.sleep(0.2)
    progress_bar.progress(100, text="‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    time.sleep(0.3)
    progress_bar.empty()

    return df

@st.cache_data(show_spinner=False)
def _load_excel_file(file_bytes, sheet_name):
    """–ö–µ—à–æ–≤–∞–Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è Excel —Ñ–∞–π–ª—É"""
    from io import BytesIO
    import time

    progress_bar = st.progress(0, text="üìÇ –í—ñ–¥–∫—Ä–∏—Ç—Ç—è —Ñ–∞–π–ª—É...")
    time.sleep(0.2)
    progress_bar.progress(30, text="üìä –ß–∏—Ç–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö...")

    df = pd.read_excel(BytesIO(file_bytes), sheet_name=sheet_name, nrows=100000)

    progress_bar.progress(90, text="‚úÖ –§—ñ–Ω–∞–ª—ñ–∑–∞—Ü—ñ—è...")
    time.sleep(0.2)
    progress_bar.progress(100, text="‚úÖ –§–∞–π–ª –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ!")
    time.sleep(0.3)
    progress_bar.empty()

    return df

def load_and_process_data(uploaded_file):
    if uploaded_file is None:
        st.info("üëÜ –ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ Excel —Ñ–∞–π–ª –¥–ª—è –ø–æ—á–∞—Ç–∫—É —Ä–æ–±–æ—Ç–∏")
        return None, False

    try:
        file_size = len(uploaded_file.read())
        uploaded_file.seek(0)

        if file_size > 50 * 1024 * 1024:
            st.error("‚ùå –§–∞–π–ª –∑–∞–Ω–∞–¥—Ç–æ –≤–µ–ª–∏–∫–∏–π. –ú–∞–∫—Å–∏–º—É–º: 50MB")
            return None, False

        # –í–∏–∑–Ω–∞—á–∞—î–º–æ –∞—Ä–∫—É—à—ñ
        file_bytes = uploaded_file.read()
        uploaded_file.seek(0)
        excel_file = pd.ExcelFile(uploaded_file)
        selected_sheet = st.selectbox("–û–±–µ—Ä—ñ—Ç—å –∞—Ä–∫—É—à:", excel_file.sheet_names) if len(excel_file.sheet_names) > 1 else excel_file.sheet_names[0]

        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∫–µ—à–æ–≤–∞–Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
        df = _load_excel_file(file_bytes, selected_sheet)
        if len(df) == 100000:
            st.warning("‚ö†Ô∏è –§–∞–π–ª –æ–±—Ä—ñ–∑–∞–Ω–æ –¥–æ 100,000 —Ä—è–¥–∫—ñ–≤")

        st.success(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(df)} —Ä—è–¥–∫—ñ–≤")
        
        # –°–ø—ñ–≤—Å—Ç–∞–≤–ª–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–æ–∫
        available_cols = list(df.columns)
        col1, col2 = st.columns(2)

        with col1:
            date_col = st.selectbox("–î–∞—Ç–∞:", available_cols, index=next((i for i, col in enumerate(available_cols) if any(word in col.lower() for word in ['–¥–∞—Ç', 'date'])), 0))
            art_col = st.selectbox("–ê—Ä—Ç–∏–∫—É–ª:", available_cols, index=next((i for i, col in enumerate(available_cols) if any(word in col.lower() for word in ['–∞—Ä—Ç', 'art'])), 0))
            qty_col = st.selectbox("–ö—ñ–ª—å–∫—ñ—Å—Ç—å:", available_cols, index=next((i for i, col in enumerate(available_cols) if any(word in col.lower() for word in ['–∫–æ–ª', '–∫—ñ–ª', 'qty', '–∫—ñ–ª—å–∫—ñ—Å—Ç—å', '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ'])), 0))

        with col2:
            magazin_col = st.selectbox("–ú–∞–≥–∞–∑–∏–Ω:", available_cols, index=next((i for i, col in enumerate(available_cols) if any(word in col.lower() for word in ['–º–∞–≥', 'magazin', '–º–∞–≥–∞–∑–∏–Ω'])), 0))
            name_col = st.selectbox("–ù–∞–∑–≤–∞:", available_cols, index=next((i for i, col in enumerate(available_cols) if any(word in col.lower() for word in ['–Ω–∞–∑–≤', 'name', '–Ω–∞–∑–≤–∞', '–Ω–∞–∑–≤–∞–Ω–∏–µ'])), 0))
            segment_col = st.selectbox("–°–µ–≥–º–µ–Ω—Ç (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ):", ['–ë–µ–∑ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—ó'] + available_cols)
        
        # –ü–µ—Ä–µ–π–º–µ–Ω—É–≤–∞–Ω–Ω—è –∫–æ–ª–æ–Ω–æ–∫
        column_mapping = {date_col: 'Data', art_col: 'Art', qty_col: 'Qty', magazin_col: 'Magazin', name_col: 'Name'}
        if segment_col != '–ë–µ–∑ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—ó':
            column_mapping[segment_col] = 'Segment'

        df = df.rename(columns=column_mapping)

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –æ–±–æ–≤'—è–∑–∫–æ–≤–∏—Ö –∫–æ–ª–æ–Ω–æ–∫
        required_cols = ['Data', 'Art', 'Qty', 'Magazin', 'Name']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            st.error(f"‚ùå –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}")
            return None, False

        # –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –ø–æ —Å–µ–≥–º–µ–Ω—Ç—É
        if 'Segment' in df.columns:
            st.subheader("üéØ –í–∏–±—ñ—Ä —Å–µ–≥–º–µ–Ω—Ç–∞")
            unique_segments = sorted(df['Segment'].dropna().unique())
            selected_segment = st.selectbox("–°–µ–≥–º–µ–Ω—Ç:", ['–í—Å—ñ —Å–µ–≥–º–µ–Ω—Ç–∏'] + list(unique_segments))

            if selected_segment != '–í—Å—ñ —Å–µ–≥–º–µ–Ω—Ç–∏':
                df = df[df['Segment'] == selected_segment].copy()
                st.success(f"‚úÖ –û–±—Ä–∞–Ω–æ —Å–µ–≥–º–µ–Ω—Ç: {selected_segment}")

        with st.expander("üìä –ü–æ–ø–µ—Ä–µ–¥–Ω—ñ–π –ø–µ—Ä–µ–≥–ª—è–¥"):
            st.dataframe(df.head())
            col1, col2, col3 = st.columns(3)
            with col1: st.metric("–ó–∞–ø–∏—Å—ñ–≤", len(df))
            with col2: st.metric("–ê—Ä—Ç–∏–∫—É–ª—ñ–≤", df['Art'].nunique())
            with col3:
                try:
                    date_min = pd.to_datetime(df['Data'], errors='coerce').min()
                    date_max = pd.to_datetime(df['Data'], errors='coerce').max()
                    st.metric("–ü–µ—Ä—ñ–æ–¥", f"{date_min.strftime('%Y-%m-%d')} - {date_max.strftime('%Y-%m-%d')}")
                except:
                    st.metric("–ü–µ—Ä—ñ–æ–¥", "–ü–æ–º–∏–ª–∫–∞ –¥–∞—Ç")

        return df, True

    except Exception as e:
        st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {str(e)}")
        return None, False

def load_from_google_sheets(sheets_url):
    """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑ –ø—É–±–ª—ñ—á–Ω–æ—ó Google Sheets —Ç–∞–±–ª–∏—Ü—ñ"""
    if not sheets_url or sheets_url.strip() == "":
        st.info("üëÜ –í–≤–µ–¥—ñ—Ç—å –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ Google Sheets")
        return None, False

    try:
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∫–µ—à–æ–≤–∞–Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö
        df = _fetch_google_sheets_data(sheets_url)

        if len(df) == 100000:
            st.warning("‚ö†Ô∏è –§–∞–π–ª –æ–±—Ä—ñ–∑–∞–Ω–æ –¥–æ 100,000 —Ä—è–¥–∫—ñ–≤")

        st.success(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(df)} —Ä—è–¥–∫—ñ–≤ –∑ Google Sheets")

        # –°–ø—ñ–≤—Å—Ç–∞–≤–ª–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–æ–∫ (—ñ–¥–µ–Ω—Ç–∏—á–Ω–æ load_and_process_data)
        available_cols = list(df.columns)
        col1, col2 = st.columns(2)

        with col1:
            date_col = st.selectbox("–î–∞—Ç–∞:", available_cols, index=next((i for i, col in enumerate(available_cols) if any(word in col.lower() for word in ['–¥–∞—Ç', 'date'])), 0), key="gs_date")
            art_col = st.selectbox("–ê—Ä—Ç–∏–∫—É–ª:", available_cols, index=next((i for i, col in enumerate(available_cols) if any(word in col.lower() for word in ['–∞—Ä—Ç', 'art'])), 0), key="gs_art")
            qty_col = st.selectbox("–ö—ñ–ª—å–∫—ñ—Å—Ç—å:", available_cols, index=next((i for i, col in enumerate(available_cols) if any(word in col.lower() for word in ['–∫–æ–ª', '–∫—ñ–ª', 'qty', '–∫—ñ–ª—å–∫—ñ—Å—Ç—å', '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ'])), 0), key="gs_qty")

        with col2:
            magazin_col = st.selectbox("–ú–∞–≥–∞–∑–∏–Ω:", available_cols, index=next((i for i, col in enumerate(available_cols) if any(word in col.lower() for word in ['–º–∞–≥', 'magazin', '–º–∞–≥–∞–∑–∏–Ω'])), 0), key="gs_magazin")
            name_col = st.selectbox("–ù–∞–∑–≤–∞:", available_cols, index=next((i for i, col in enumerate(available_cols) if any(word in col.lower() for word in ['–Ω–∞–∑–≤', 'name', '–Ω–∞–∑–≤–∞', '–Ω–∞–∑–≤–∞–Ω–∏–µ'])), 0), key="gs_name")
            segment_col = st.selectbox("–°–µ–≥–º–µ–Ω—Ç (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ):", ['–ë–µ–∑ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—ó'] + available_cols, key="gs_segment")

        # –ü–µ—Ä–µ–π–º–µ–Ω—É–≤–∞–Ω–Ω—è –∫–æ–ª–æ–Ω–æ–∫
        column_mapping = {date_col: 'Data', art_col: 'Art', qty_col: 'Qty', magazin_col: 'Magazin', name_col: 'Name'}
        if segment_col != '–ë–µ–∑ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—ó':
            column_mapping[segment_col] = 'Segment'

        df = df.rename(columns=column_mapping)

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –æ–±–æ–≤'—è–∑–∫–æ–≤–∏—Ö –∫–æ–ª–æ–Ω–æ–∫
        required_cols = ['Data', 'Art', 'Qty', 'Magazin', 'Name']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            st.error(f"‚ùå –í—ñ–¥—Å—É—Ç–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}")
            return None, False

        # –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –ø–æ —Å–µ–≥–º–µ–Ω—Ç—É
        if 'Segment' in df.columns:
            st.subheader("üéØ –í–∏–±—ñ—Ä —Å–µ–≥–º–µ–Ω—Ç–∞")
            unique_segments = sorted(df['Segment'].dropna().unique())
            selected_segment = st.selectbox("–°–µ–≥–º–µ–Ω—Ç:", ['–í—Å—ñ —Å–µ–≥–º–µ–Ω—Ç–∏'] + list(unique_segments), key="gs_segment_filter")

            if selected_segment != '–í—Å—ñ —Å–µ–≥–º–µ–Ω—Ç–∏':
                df = df[df['Segment'] == selected_segment].copy()
                st.success(f"‚úÖ –û–±—Ä–∞–Ω–æ —Å–µ–≥–º–µ–Ω—Ç: {selected_segment}")

        with st.expander("üìä –ü–æ–ø–µ—Ä–µ–¥–Ω—ñ–π –ø–µ—Ä–µ–≥–ª—è–¥"):
            st.dataframe(df.head())
            col1, col2, col3 = st.columns(3)
            with col1: st.metric("–ó–∞–ø–∏—Å—ñ–≤", len(df))
            with col2: st.metric("–ê—Ä—Ç–∏–∫—É–ª—ñ–≤", df['Art'].nunique())
            with col3:
                try:
                    date_min = pd.to_datetime(df['Data'], errors='coerce').min()
                    date_max = pd.to_datetime(df['Data'], errors='coerce').max()
                    st.metric("–ü–µ—Ä—ñ–æ–¥", f"{date_min.strftime('%Y-%m-%d')} - {date_max.strftime('%Y-%m-%d')}")
                except:
                    st.metric("–ü–µ—Ä—ñ–æ–¥", "–ü–æ–º–∏–ª–∫–∞ –¥–∞—Ç")

        return df, True

    except Exception as e:
        st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑ Google Sheets: {str(e)}")
        st.info("üí° –ü–µ—Ä–µ–∫–æ–Ω–∞–π—Ç–µ—Å—è, —â–æ —Ç–∞–±–ª–∏—Ü—è –º–∞—î –ø—É–±–ª—ñ—á–Ω–∏–π –¥–æ—Å—Ç—É–ø")
        return None, False

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –≤ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ –≤—ñ–¥ –æ–±—Ä–∞–Ω–æ–≥–æ –¥–∂–µ—Ä–µ–ª–∞ –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º session_state
# –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ –∑–º—ñ–Ω–∏–ª–æ—Å—å –¥–∂–µ—Ä–µ–ª–æ –¥–∞–Ω–∏—Ö
if st.session_state.data_source_type != data_source:
    st.session_state.loaded_data = None  # –°–∫–∏–¥–∞—î–º–æ –∫–µ—à –ø—Ä–∏ –∑–º—ñ–Ω—ñ –¥–∂–µ—Ä–µ–ª–∞
    st.session_state.data_source_type = data_source

# –Ø–∫—â–æ –¥–∞–Ω—ñ –≤–∂–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ —ñ –¥–∂–µ—Ä–µ–ª–æ –Ω–µ –∑–º—ñ–Ω–∏–ª–æ—Å—å, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∫–µ—à–æ–≤–∞–Ω—ñ
if st.session_state.loaded_data is not None:
    df, data_loaded = st.session_state.loaded_data
    if data_loaded:
        st.info("‚ÑπÔ∏è –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è —Ä–∞–Ω—ñ—à–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ –¥–∞–Ω—ñ")
else:
    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –Ω–æ–≤—ñ –¥–∞–Ω—ñ
    if data_source == "–õ–æ–∫–∞–ª—å–Ω–∏–π —Ñ–∞–π–ª":
        df, data_loaded = load_and_process_data(uploaded_file)
    else:
        df, data_loaded = load_from_google_sheets(sheets_url)

    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ session_state
    if data_loaded:
        st.session_state.loaded_data = (df, data_loaded)

if data_loaded:
    st.header("üöÄ –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª—ñ–∑—É")
    if st.button("‚ñ∂Ô∏è –ü–û–ß–ê–¢–ò –ê–ù–ê–õ–Ü–ó", type="primary", use_container_width=True):
        st.session_state.run_analysis = True

    if not st.session_state.get('run_analysis', False):
        st.info("üëÜ –ù–∞—Ç–∏—Å–Ω—ñ—Ç—å –∫–Ω–æ–ø–∫—É –¥–ª—è –∑–∞–ø—É—Å–∫—É –∞–Ω–∞–ª—ñ–∑—É")
        st.stop()
else:
    st.stop()

# === –û–°–ù–û–í–ù–ê –û–ë–†–û–ë–ö–ê ===
def process_data(df):
    with st.spinner("üîÑ –û–±—Ä–æ–±–∫–∞ –¥–∞–Ω–∏—Ö..."):
        # –û—á–∏—â–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö
        df['Data'] = pd.to_datetime(df['Data'], dayfirst=True, errors='coerce')
        df = df.dropna(subset=['Data'])
        df['Qty'] = pd.to_numeric(df['Qty'], errors='coerce').fillna(0)
        df = df[df['Qty'] >= 0]

        if len(df) == 0:
            st.error("‚ùå –ù–µ–º–∞—î –≤–∞–ª—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö")
            st.stop()

        df['year_week'] = df['Data'].dt.strftime('%Y-%U')

        # –û–±–º–µ–∂–µ–Ω–Ω—è –∞—Ä—Ç–∏–∫—É–ª—ñ–≤
        all_arts = df['Art'].unique()
        if len(all_arts) > 5000:
            st.warning("‚ö†Ô∏è –û–±—Ä–æ–±–ª—è—î–º–æ —Ç–æ–ø-5000 –∞—Ä—Ç–∏–∫—É–ª—ñ–≤ –∑–∞ –ø—Ä–æ–¥–∞–∂–∞–º–∏")
            top_arts = df.groupby('Art')['Qty'].sum().nlargest(5000).index
            all_arts = top_arts
            df = df[df['Art'].isin(all_arts)]

        # –ê–≥—Ä–µ–≥–∞—Ü—ñ—è –ø–æ —Ç–∏–∂–Ω—è—Ö
        weekly = df.groupby(['Art', 'year_week'])['Qty'].sum().reset_index()
        unique_weeks = sorted(df['year_week'].unique())
        all_weeks = pd.MultiIndex.from_product([all_arts, unique_weeks], names=['Art', 'year_week'])
        weekly = weekly.set_index(['Art', 'year_week']).reindex(all_weeks, fill_value=0).reset_index()

        return df, weekly, all_arts, unique_weeks

def calculate_abc_xyz_analysis(df):
    # ABC –∞–Ω–∞–ª—ñ–∑
    abc_analysis = df.groupby('Art').agg({
        'Qty': ['sum', 'mean', 'std'],
        'Data': ['min', 'max']
    }).reset_index()
    
    abc_analysis.columns = ['Art', 'total_qty', 'avg_qty', 'std_qty', 'first_sale', 'last_sale']
    abc_analysis['days_in_catalog'] = (abc_analysis['last_sale'] - abc_analysis['first_sale']).dt.days + 1

    # ABC –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó (–≤–∏–ø—Ä–∞–≤–ª–µ–Ω–æ: —Å–æ—Ä—Ç—É–≤–∞–Ω–Ω—è –ø–µ—Ä–µ–¥ –∫—É–º—É–ª—è—Ç–∏–≤–Ω–∏–º —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫–æ–º)
    abc_analysis = abc_analysis.sort_values('total_qty', ascending=False).reset_index(drop=True)
    total_sum = abc_analysis['total_qty'].sum()

    # –ó–∞—Ö–∏—Å—Ç –≤—ñ–¥ –¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ –Ω—É–ª—å
    if total_sum > 0:
        abc_analysis['cum_qty'] = abc_analysis['total_qty'].cumsum()
        abc_analysis['cum_qty_pct'] = abc_analysis['cum_qty'] / total_sum
    else:
        abc_analysis['cum_qty'] = 0
        abc_analysis['cum_qty_pct'] = 0

    def get_abc_category(cum_pct):
        if cum_pct <= 0.8: return 'A'
        elif cum_pct <= 0.95: return 'B'
        else: return 'C'

    abc_analysis['abc_category'] = abc_analysis['cum_qty_pct'].apply(get_abc_category)

    # XYZ –∞–Ω–∞–ª—ñ–∑ (–≤–∏–ø—Ä–∞–≤–ª–µ–Ω–æ: –æ–±—Ä–æ–±–∫–∞ –Ω—É–ª—å–æ–≤–∏—Ö –∑–Ω–∞—á–µ–Ω—å)
    abc_analysis['coefficient_variation'] = np.where(
        abc_analysis['avg_qty'] > 0,
        abc_analysis['std_qty'] / abc_analysis['avg_qty'],
        999  # –í–µ–ª–∏–∫–µ –∑–Ω–∞—á–µ–Ω–Ω—è –¥–ª—è —Ç–æ–≤–∞—Ä—ñ–≤ –±–µ–∑ –ø—Ä–æ–¥–∞–∂—ñ–≤
    )

    def get_xyz_category(cv):
        if cv <= 0.1: return 'X'  # –°—Ç–∞–±—ñ–ª—å–Ω–∏–π –ø–æ–ø–∏—Ç
        elif cv <= 0.25: return 'Y'  # –ü–æ–º—ñ—Ä–Ω–æ –º—ñ–Ω–ª–∏–≤–∏–π
        else: return 'Z'  # –ù–µ—Å—Ç–∞–±—ñ–ª—å–Ω–∏–π –ø–æ–ø–∏—Ç

    abc_analysis['xyz_category'] = abc_analysis['coefficient_variation'].apply(get_xyz_category)

    return abc_analysis

def calculate_features(weekly, df):
    def compute_features(group):
        sorted_group = group.sort_values('year_week')
        qty_series = sorted_group['Qty'].values
        
        if len(qty_series) == 0:
            return pd.Series({
                'ma_3': 0, 
                'ma_6': 0, 
                'consecutive_zeros': 0,
                'zero_weeks_12': 0, 
                'trend': 0
            })


        # –ö–æ–≤–∑–Ω—ñ —Å–µ—Ä–µ–¥–Ω—ñ
        qty_series_pd = pd.Series(qty_series)
        ma_3 = qty_series_pd.rolling(3, min_periods=1).mean().iloc[-1]
        ma_6 = qty_series_pd.rolling(6, min_periods=1).mean().iloc[-1]

        # –ü–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ –Ω—É–ª—ñ –∑ –∫—ñ–Ω—Ü—è
        consecutive_zeros = 0
        for val in reversed(qty_series):
            if val == 0:
                consecutive_zeros += 1
            else:
                break

        # –ù—É–ª—ñ –∑–∞ –æ—Å—Ç–∞–Ω–Ω—ñ 12 —Ç–∏–∂–Ω—ñ–≤
        zero_weeks_12 = int(np.sum(qty_series[-12:] == 0)) if len(qty_series) >= 12 else int(np.sum(qty_series == 0))

        # –¢—Ä–µ–Ω–¥
        trend = 0
        if len(qty_series) >= 4:
            try:
                x = np.arange(len(qty_series))
                coeffs = np.polyfit(x, qty_series, 1)
                trend = float(coeffs[0])
            except:
                trend = 0
        
        return pd.Series({
            'ma_3': float(ma_3), 
            'ma_6': float(ma_6), 
            'consecutive_zeros': int(consecutive_zeros),
            'zero_weeks_12': int(zero_weeks_12), 
            'trend': float(trend)
        })
    
    # –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ —Ñ—É–Ω–∫—Ü—ñ—é —ñ –æ—Ç—Ä–∏–º—É—î–º–æ DataFrame –∑ Art –≤ —ñ–Ω–¥–µ–∫—Å—ñ
    features = weekly.groupby('Art').apply(compute_features, include_groups=False).reset_index()

    # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ —á–∞—Å—Ç–∫–∏ –º–∞–≥–∞–∑–∏–Ω—ñ–≤ –±–µ–∑ –ø—Ä–æ–¥–∞–∂—ñ–≤
    total_stores = df['Magazin'].nunique()

    if total_stores == 0:
        st.error("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –º–∞–≥–∞–∑–∏–Ω—ñ–≤ –≤ –¥–∞–Ω–∏—Ö")
        st.stop()

    # –ú–∞–≥–∞–∑–∏–Ω–∏ –∑ –ø—Ä–æ–¥–∞–∂–∞–º–∏ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –∞—Ä—Ç–∏–∫—É–ª–∞
    stores_with_sales = df[df['Qty'] > 0].groupby('Art')['Magazin'].nunique().reset_index()
    stores_with_sales.columns = ['Art', 'stores_with_sales']
    stores_with_sales['no_store_ratio'] = 1 - (stores_with_sales['stores_with_sales'] / total_stores)

    features = features.merge(stores_with_sales[['Art', 'no_store_ratio']], on='Art', how='left')
    features['no_store_ratio'] = features['no_store_ratio'].fillna(1.0)

    return features

def create_ml_model(features, abc_analysis):
    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –º—ñ—Ç–æ–∫ –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è (–í–ò–ü–†–ê–í–õ–ï–ù–ê –õ–û–ì–Ü–ö–ê)
    def create_labels(row):
        score = 0

        # –ö–∞—Ç–µ–≥–æ—Ä—ñ—è C - –∞–≥—Ä–µ—Å–∏–≤–Ω—ñ –∫—Ä–∏—Ç–µ—Ä—ñ—ó
        if row['abc_category'] == 'C':
            if row['consecutive_zeros'] >= zero_weeks_threshold:
                score += 3
            elif row['zero_weeks_12'] >= zero_weeks_threshold // 2:
                score += 2

            if row['no_store_ratio'] > max_store_ratio:
                score += 2

            if row['total_qty'] < min_total_sales:
                score += 2

            if row['trend'] < -0.1:
                score += 1

        # –ö–∞—Ç–µ–≥–æ—Ä—ñ—è B - –ø–æ–º—ñ—Ä–Ω—ñ –∫—Ä–∏—Ç–µ—Ä—ñ—ó (–í–ò–ü–†–ê–í–õ–ï–ù–û)
        elif row['abc_category'] == 'B':
            if row['consecutive_zeros'] >= zero_weeks_threshold * 2:  # 24 —Ç–∏–∂–Ω—ñ
                score += 3
            elif row['consecutive_zeros'] >= zero_weeks_threshold:  # 12 —Ç–∏–∂–Ω—ñ–≤
                score += 2

            if row['no_store_ratio'] > max_store_ratio:  # 85%
                score += 2

            if row['total_qty'] < min_total_sales * 2:  # 10 –æ–¥–∏–Ω–∏—Ü—å
                score += 1

            if row['trend'] < -0.1:
                score += 1

        # –ö–∞—Ç–µ–≥–æ—Ä—ñ—è A - —Ç—ñ–ª—å–∫–∏ –∫—Ä–∏—Ç–∏—á–Ω—ñ –≤–∏–ø–∞–¥–∫–∏
        elif row['abc_category'] == 'A':
            if row['consecutive_zeros'] >= zero_weeks_threshold * 3:  # 36 —Ç–∏–∂–Ω—ñ–≤
                score += 2
            if row['no_store_ratio'] > 0.95:  # 95%
                score += 1

        # –ö—Ä–∏—Ç–∏—á–Ω—ñ –≤–∏–ø–∞–¥–∫–∏ –¥–ª—è –ë–£–î–¨-–Ø–ö–û–á –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó
        if row['consecutive_zeros'] >= zero_weeks_threshold * 2 and row['no_store_ratio'] > max_store_ratio:
            score += 2  # –ü–æ—Å–∏–ª–µ–Ω–Ω—è –¥–ª—è –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó —Ñ–∞–∫—Ç–æ—Ä—ñ–≤

        return 1 if score >= 4 else 0

    # –û–±'—î–¥–Ω–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö
    final_features = features.merge(
        abc_analysis[['Art', 'total_qty', 'abc_category', 'last_sale']],
        on='Art',
        how='left'
    )
    final_features['label'] = final_features.apply(create_labels, axis=1)

    # –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ
    feature_cols = ['ma_3', 'ma_6', 'consecutive_zeros', 'zero_weeks_12', 'trend', 'no_store_ratio', 'total_qty']
    X = final_features[feature_cols].fillna(0)
    y = final_features['label']
    
    st.write(f"**–†–æ–∑–ø–æ–¥—ñ–ª:** –ó–Ω—è—Ç–∏: {y.sum()}, –ó–∞–ª–∏—à–∏—Ç–∏: {len(y) - y.sum()}")

    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ –Ω–∞–≤—á–∞–Ω–Ω—è (–ø–æ–∫—Ä–∞—â–µ–Ω–æ: –º—ñ–Ω—ñ–º—É–º 2 –∑—Ä–∞–∑–∫–∏ –≤ –∫–æ–∂–Ω–æ–º—É –∫–ª–∞—Å—ñ)
    if len(y.unique()) > 1 and y.sum() >= 2 and len(y) - y.sum() >= 2:
        try:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y,
                stratify=y,
                random_state=42,
                test_size=0.3
            )

            clf = RandomForestClassifier(
                n_estimators=30,
                random_state=42,
                class_weight='balanced' if use_balanced_model else None,
                max_depth=8,
                min_samples_split=5,
                n_jobs=1
            )

            clf.fit(X_train, y_train)
            final_features['prob_dying'] = clf.predict_proba(X)[:, 1] * 100
            test_score = clf.score(X_test, y_test)

        except Exception as e:
            st.warning(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ ML: {e}. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø—Ä–æ—Å—Ç—É –ª–æ–≥—ñ–∫—É.")
            final_features['prob_dying'] = final_features['label'].astype(float) * 100
            test_score = 0.0
    else:
        st.warning("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –¥–ª—è ML. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø—Ä–æ—Å—Ç—É –ª–æ–≥—ñ–∫—É.")
        final_features['prob_dying'] = final_features['label'].astype(float) * 100
        test_score = 0.0

    return final_features, test_score

def create_prophet_forecasts(df, abc_analysis):
    if not PROPHET_AVAILABLE:
        return pd.DataFrame()
    
    try:
        with st.spinner("üìà –ü—Ä–æ–≥–Ω–æ–∑–∏ Prophet..."):
            top_arts = abc_analysis.nlargest(TOP_N, 'total_qty')['Art']
            forecasts = []
            
            for art in top_arts:
                try:
                    sales = df[df['Art'] == art].groupby('Data')['Qty'].sum().reset_index()
                    if len(sales) < 8: 
                        continue
                    
                    sales.columns = ['ds', 'y']
                    
                    model = Prophet(
                        daily_seasonality=False, 
                        weekly_seasonality=False, 
                        yearly_seasonality=False,
                        changepoint_prior_scale=0.05
                    )
                    
                    with warnings.catch_warnings():
                        warnings.simplefilter("ignore")
                        model.fit(sales)
                        future = model.make_future_dataframe(periods=30)
                        forecast = model.predict(future)
                    
                    median_30 = max(0, forecast.tail(30)['yhat'].median())
                    forecasts.append({'Art': art, 'forecast_30_median': float(median_30)})
                    
                except Exception as e:
                    continue
            
            return pd.DataFrame(forecasts)
            
    except Exception as e:
        st.warning(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ Prophet: {e}")
        return pd.DataFrame()

def get_recommendations(row):
    # –§–æ—Ä–º—É–≤–∞–Ω–Ω—è –ø—Ä–∏—á–∏–Ω
    reasons = []

    if row['abc_category'] == 'C':
        reasons.append("–ö–∞—Ç–µ–≥–æ—Ä—ñ—è C")
    elif row['abc_category'] == 'B':
        reasons.append("–ö–∞—Ç–µ–≥–æ—Ä—ñ—è B")

    if row['consecutive_zeros'] >= zero_weeks_threshold * 2:
        reasons.append(f"–ë–µ–∑ –ø—Ä–æ–¥–∞–∂—ñ–≤ {int(row['consecutive_zeros'])} —Ç–∏–∂–Ω—ñ–≤ (–∫—Ä–∏—Ç–∏—á–Ω–æ!)")
    elif row['consecutive_zeros'] >= zero_weeks_threshold:
        reasons.append(f"–ë–µ–∑ –ø—Ä–æ–¥–∞–∂—ñ–≤ {int(row['consecutive_zeros'])} —Ç–∏–∂–Ω—ñ–≤")

    if row['zero_weeks_12'] >= zero_weeks_threshold // 2:
        reasons.append(f"–ó 12 —Ç–∏–∂–Ω—ñ–≤ {int(row['zero_weeks_12'])} –±–µ–∑ –ø—Ä–æ–¥–∞–∂—ñ–≤")

    if row['no_store_ratio'] > max_store_ratio:
        stores_with_sales_pct = (1 - row['no_store_ratio']) * 100
        reasons.append(f"–ü—Ä–æ–¥–∞–∂—ñ –≤ {stores_with_sales_pct:.0f}% –º–∞–≥–∞–∑–∏–Ω—ñ–≤")

    if row['total_qty'] < min_total_sales:
        reasons.append(f"–ú–∞–ª–∏–π –æ–±—Å—è–≥ ({row['total_qty']:.1f})")
    elif row['total_qty'] < min_total_sales * 2:
        reasons.append(f"–ù–∏–∑—å–∫–∏–π –æ–±—Å—è–≥ ({row['total_qty']:.1f})")

    if row['trend'] < -0.1:
        reasons.append("–ù–µ–≥–∞—Ç–∏–≤–Ω–∏–π —Ç—Ä–µ–Ω–¥")

    # –î–æ–¥–∞—î–º–æ –¥–∞—Ç—É –æ—Å—Ç–∞–Ω–Ω—å–æ–≥–æ –ø—Ä–æ–¥–∞–∂—É
    if pd.notnull(row.get('last_sale')):
        last_sale_str = row['last_sale'].strftime('%Y-%m-%d')
        reasons.append(f"–û—Å—Ç–∞–Ω–Ω—ñ–π –ø—Ä–æ–¥–∞–∂: {last_sale_str}")

    reason = "; ".join(reasons) if reasons else "–°—Ç–∞–±—ñ–ª—å–Ω—ñ –ø—Ä–æ–¥–∞–∂—ñ"

    # –ö–†–ò–¢–ò–ß–ù–Ü –í–ò–ü–ê–î–ö–ò - –ø–µ—Ä–µ–≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –Ω–µ–∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ ML
    # 1. –ï–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ —Ç—Ä–∏–≤–∞–ª–∞ –≤—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å –ø—Ä–æ–¥–∞–∂—ñ–≤
    if row['consecutive_zeros'] >= zero_weeks_threshold * 3:  # 36 —Ç–∏–∂–Ω—ñ–≤
        return reason, "üö´ –ó–Ω—è—Ç–∏"

    # 2. –ö–∞—Ç–µ–≥–æ—Ä—ñ—è C –∑ –ø–µ—Ä–µ–≤–∏—â–µ–Ω–Ω—è–º –≤—Å—ñ—Ö –ø–æ—Ä–æ–≥—ñ–≤
    if (row['abc_category'] == 'C' and
        row['consecutive_zeros'] >= zero_weeks_threshold and
        row['total_qty'] < min_total_sales and
        row['no_store_ratio'] > max_store_ratio):
        return reason, "üö´ –ó–Ω—è—Ç–∏"

    # 3. –ö–∞—Ç–µ–≥–æ—Ä—ñ—è B –∑ –∫—Ä–∏—Ç–∏—á–Ω–∏–º–∏ –ø–æ–∫–∞–∑–Ω–∏–∫–∞–º–∏
    if (row['abc_category'] == 'B' and
        row['consecutive_zeros'] >= zero_weeks_threshold * 2 and
        row['no_store_ratio'] > max_store_ratio):
        return reason, "üö´ –ó–Ω—è—Ç–∏"

    # 4. –¢—Ä–∏–≤–∞–ª–∞ –≤—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å + –Ω–∏–∑—å–∫–µ –ø–æ—à–∏—Ä–µ–Ω–Ω—è –¥–ª—è B
    if (row['abc_category'] == 'B' and
        row['consecutive_zeros'] >= zero_weeks_threshold * 1.5 and
        row['no_store_ratio'] > 0.85 and
        row['total_qty'] < min_total_sales * 2):
        return reason, "‚ö†Ô∏è –°–ø–æ—Å—Ç–µ—Ä—ñ–≥–∞—Ç–∏"

    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞ –ª–æ–≥—ñ–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤—ñ ML
    prob_threshold_pct = final_threshold * 100

    if row['prob_dying'] > prob_threshold_pct:
        return reason, "üö´ –ó–Ω—è—Ç–∏"
    elif row['prob_dying'] > prob_threshold_pct * 0.7:
        return reason, "‚ö†Ô∏è –°–ø–æ—Å—Ç–µ—Ä—ñ–≥–∞—Ç–∏"

    # –î–æ–¥–∞—Ç–∫–æ–≤—ñ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –¥–ª—è "–°–ø–æ—Å—Ç–µ—Ä—ñ–≥–∞—Ç–∏"
    if (row['consecutive_zeros'] >= zero_weeks_threshold and
        row['no_store_ratio'] > 0.75):
        return reason, "‚ö†Ô∏è –°–ø–æ—Å—Ç–µ—Ä—ñ–≥–∞—Ç–∏"

    return reason, "‚úÖ –ó–∞–ª–∏—à–∏—Ç–∏"

# –í–∏–∫–æ–Ω–∞–Ω–Ω—è –∞–Ω–∞–ª—ñ–∑—É
df, weekly, all_arts, unique_weeks = process_data(df)
abc_analysis = calculate_abc_xyz_analysis(df)
features = calculate_features(weekly, df)
final_features, test_score = create_ml_model(features, abc_analysis)
forecast_df = create_prophet_forecasts(df, abc_analysis)

# –§—ñ–Ω–∞–ª—å–Ω–∞ —Ç–∞–±–ª–∏—Ü—è
final = final_features.merge(abc_analysis[['Art', 'xyz_category', 'last_sale']], on='Art', how='left')

# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø–µ—Ä–µ–¥ –º–µ—Ä–¥–∂–µ–º forecast_df
if not forecast_df.empty:
    final = final.merge(forecast_df, on='Art', how='left')

# –û–±—Ä–æ–±–∫–∞ –ø—É—Å—Ç–∏—Ö Name
final = final.merge(df[['Art', 'Name']].drop_duplicates(), on='Art', how='left')
final['Name'] = final['Name'].fillna('–ë–µ–∑ –Ω–∞–∑–≤–∏')

# –û—Ç—Ä–∏–º–∞–Ω–Ω—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π
recommendations = final.apply(get_recommendations, axis=1)
final['–ü—Ä–∏—á–∏–Ω–∞'] = [rec[0] for rec in recommendations]
final['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è'] = [rec[1] for rec in recommendations]

# === –†–ï–ó–£–õ–¨–¢–ê–¢–ò ===
st.header("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∞–Ω–∞–ª—ñ–∑—É")

total_products = len(final)
candidates_remove = len(final[final['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è'] == "üö´ –ó–Ω—è—Ç–∏"])
candidates_watch = len(final[final['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è'] == "‚ö†Ô∏è –°–ø–æ—Å—Ç–µ—Ä—ñ–≥–∞—Ç–∏"])
candidates_keep = len(final[final['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è'] == "‚úÖ –ó–∞–ª–∏—à–∏—Ç–∏"])

col1, col2, col3, col4 = st.columns(4)
with col1: st.metric("–í—Å—å–æ–≥–æ —Ç–æ–≤–∞—Ä—ñ–≤", total_products)
with col2: st.metric("–î–æ –∑–Ω—è—Ç—Ç—è", candidates_remove, f"{candidates_remove/total_products*100:.1f}%")
with col3: st.metric("–°–ø–æ—Å—Ç–µ—Ä—ñ–≥–∞—Ç–∏", candidates_watch, f"{candidates_watch/total_products*100:.1f}%")
with col4: st.metric("–¢–æ—á–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ", f"{test_score:.2f}" if test_score > 0 else "N/A")

# ABC/XYZ —Ä–æ–∑–ø–æ–¥—ñ–ª
st.subheader("üìà ABC/XYZ –∞–Ω–∞–ª—ñ–∑")
abc_dist = final['abc_category'].value_counts()
xyz_dist = final['xyz_category'].value_counts()

col1, col2 = st.columns(2)
with col1:
    st.write("**ABC –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó:**")
    st.write(f"A: {abc_dist.get('A', 0)}, B: {abc_dist.get('B', 0)}, C: {abc_dist.get('C', 0)}")
with col2:
    st.write("**XYZ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó:**")
    st.write(f"X: {xyz_dist.get('X', 0)}, Y: {xyz_dist.get('Y', 0)}, Z: {xyz_dist.get('Z', 0)}")

# === –ù–û–í–ò–ô –†–û–ó–î–Ü–õ: –°–¢–ê–¢–ò–°–¢–ò–ö–ê –î–õ–Ø –ü–†–û–î–ê–ñ–Ü–í –¢–ê –ú–ê–†–ö–ï–¢–ò–ù–ì–£ ===
st.header("üìà –ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ –¥–ª—è –≤—ñ–¥–¥—ñ–ª—É –ø—Ä–æ–¥–∞–∂—ñ–≤ —Ç–∞ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥—É")

# –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –º–µ—Ç—Ä–∏–∫
total_sales_volume = final['total_qty'].sum()
remove_sales_volume = final[final['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è'] == "üö´ –ó–Ω—è—Ç–∏"]['total_qty'].sum()
watch_sales_volume = final[final['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è'] == "‚ö†Ô∏è –°–ø–æ—Å—Ç–µ—Ä—ñ–≥–∞—Ç–∏"]['total_qty'].sum()
keep_sales_volume = final[final['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è'] == "‚úÖ –ó–∞–ª–∏—à–∏—Ç–∏"]['total_qty'].sum()

# 1. –ó–≤–µ–¥–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü—è –∑–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è–º–∏ —Ç–∞ ABC
st.subheader("üìä –ó–≤–µ–¥–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü—è: –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó √ó ABC –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó")

summary_pivot = pd.crosstab(
    final['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è'],
    final['abc_category'],
    values=final['total_qty'],
    aggfunc='sum',
    margins=True,
    margins_name='–†–∞–∑–æ–º'
).fillna(0).astype(int)

st.dataframe(summary_pivot.style.format("{:,}"), use_container_width=True)

# 2. –¢–∞–±–ª–∏—Ü—è –∑ –∫–ª—é—á–æ–≤–∏–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
st.subheader("üíº –ö–ª—é—á–æ–≤—ñ –±—ñ–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫–∏")

metrics_data = {
    '–ö–∞—Ç–µ–≥–æ—Ä—ñ—è': ['üö´ –ó–Ω—è—Ç–∏', '‚ö†Ô∏è –°–ø–æ—Å—Ç–µ—Ä—ñ–≥–∞—Ç–∏', '‚úÖ –ó–∞–ª–∏—à–∏—Ç–∏', '**–†–ê–ó–û–ú**'],
    '–ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–≤–∞—Ä—ñ–≤': [candidates_remove, candidates_watch, candidates_keep, total_products],
    '% –≤—ñ–¥ –∞—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç—É': [
        f"{candidates_remove/total_products*100:.1f}%",
        f"{candidates_watch/total_products*100:.1f}%",
        f"{candidates_keep/total_products*100:.1f}%",
        "100%"
    ],
    '–û–±—Å—è–≥ –ø—Ä–æ–¥–∞–∂—ñ–≤ (–æ–¥.)': [
        f"{remove_sales_volume:,.0f}",
        f"{watch_sales_volume:,.0f}",
        f"{keep_sales_volume:,.0f}",
        f"{total_sales_volume:,.0f}"
    ],
    '% –≤—ñ–¥ –æ–±–æ—Ä–æ—Ç—É': [
        f"{remove_sales_volume/total_sales_volume*100:.1f}%",
        f"{watch_sales_volume/total_sales_volume*100:.1f}%",
        f"{keep_sales_volume/total_sales_volume*100:.1f}%",
        "100%"
    ]
}

metrics_df = pd.DataFrame(metrics_data)
st.dataframe(metrics_df, use_container_width=True, hide_index=True)

# 3. –¢–æ–ø-20 —Ç–æ–≤–∞—Ä—ñ–≤ –¥–æ –∑–Ω—è—Ç—Ç—è
st.subheader("üî¥ –¢–æ–ø-20 —Ç–æ–≤–∞—Ä—ñ–≤ –¥–æ –∑–Ω—è—Ç—Ç—è (–∑–∞ –æ–±—Å—è–≥–æ–º –ø—Ä–æ–¥–∞–∂—ñ–≤)")

remove_candidates = final[final['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è'] == "üö´ –ó–Ω—è—Ç–∏"].nlargest(20, 'total_qty')
remove_display = remove_candidates[['Art', 'Name', 'abc_category', 'total_qty', 'consecutive_zeros', 'no_store_ratio', '–ü—Ä–∏—á–∏–Ω–∞']].copy()
remove_display['no_store_ratio'] = (remove_display['no_store_ratio'] * 100).round(1).astype(str) + '%'
remove_display.columns = ['–ê—Ä—Ç–∏–∫—É–ª', '–ù–∞–∑–≤–∞', 'ABC', '–û–±—Å—è–≥ –ø—Ä–æ–¥–∞–∂—ñ–≤', '–¢–∏–∂–Ω—ñ–≤ –±–µ–∑ –ø—Ä–æ–¥–∞–∂—ñ–≤', '–ú–∞–≥–∞–∑–∏–Ω—ñ–≤ –±–µ–∑ –ø—Ä–æ–¥–∞–∂—ñ–≤', '–ü—Ä–∏—á–∏–Ω–∞']

st.dataframe(remove_display, use_container_width=True, hide_index=True)

# 4. –¢–æ–≤–∞—Ä–∏ –ø—ñ–¥ —Å–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–Ω—è–º
st.subheader("üü° –¢–æ–ø-20 —Ç–æ–≤–∞—Ä—ñ–≤ –ø—ñ–¥ —Å–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–Ω—è–º")

watch_candidates = final[final['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è'] == "‚ö†Ô∏è –°–ø–æ—Å—Ç–µ—Ä—ñ–≥–∞—Ç–∏"].nlargest(20, 'total_qty')
watch_display = watch_candidates[['Art', 'Name', 'abc_category', 'total_qty', 'consecutive_zeros', 'prob_dying', '–ü—Ä–∏—á–∏–Ω–∞']].copy()
watch_display['prob_dying'] = watch_display['prob_dying'].round(1).astype(str) + '%'
watch_display.columns = ['–ê—Ä—Ç–∏–∫—É–ª', '–ù–∞–∑–≤–∞', 'ABC', '–û–±—Å—è–≥ –ø—Ä–æ–¥–∞–∂—ñ–≤', '–¢–∏–∂–Ω—ñ–≤ –±–µ–∑ –ø—Ä–æ–¥–∞–∂—ñ–≤', '–†–∏–∑–∏–∫ –∑–Ω—è—Ç—Ç—è', '–ü—Ä–∏—á–∏–Ω–∞']

st.dataframe(watch_display, use_container_width=True, hide_index=True)

# 5. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–∞–≥–∞–∑–∏–Ω–∞—Ö
st.subheader("üè™ –†–æ–∑–ø–æ–¥—ñ–ª –ø—Ä–æ–¥–∞–∂—ñ–≤ –ø–æ –º–∞–≥–∞–∑–∏–Ω–∞—Ö")

store_stats = df.groupby('Magazin').agg({
    'Art': 'nunique',
    'Qty': 'sum'
}).reset_index()
store_stats.columns = ['–ú–∞–≥–∞–∑–∏–Ω', '–£–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö —Ç–æ–≤–∞—Ä—ñ–≤', '–û–±—Å—è–≥ –ø—Ä–æ–¥–∞–∂—ñ–≤']
store_stats = store_stats.sort_values('–û–±—Å—è–≥ –ø—Ä–æ–¥–∞–∂—ñ–≤', ascending=False)

col1, col2 = st.columns([2, 1])
with col1:
    st.dataframe(store_stats, use_container_width=True, hide_index=True)
with col2:
    st.metric("–í—Å—å–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω—ñ–≤", len(store_stats))
    st.metric("–°–µ—Ä–µ–¥–Ω—ñ–π –æ–±–æ—Ä–æ—Ç", f"{store_stats['–û–±—Å—è–≥ –ø—Ä–æ–¥–∞–∂—ñ–≤'].mean():,.0f} –æ–¥.")

# === –§–Ü–õ–¨–¢–†–ò –Ü –¢–ê–ë–õ–ò–¶–Ø ===
st.subheader("üîç –§—ñ–ª—å—Ç—Ä–∏")
col1, col2, col3 = st.columns(3)

with col1:
    filter_recommendation = st.selectbox("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è:", ["–í—Å—ñ", "üö´ –ó–Ω—è—Ç–∏", "‚ö†Ô∏è –°–ø–æ—Å—Ç–µ—Ä—ñ–≥–∞—Ç–∏", "‚úÖ –ó–∞–ª–∏—à–∏—Ç–∏"])
    filter_abc = st.selectbox("ABC:", ["–í—Å—ñ", "A", "B", "C"])
with col2:
    min_prob = st.slider("–ú—ñ–Ω. –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å (%)", 0, 100, 0)
    filter_xyz = st.selectbox("XYZ:", ["–í—Å—ñ", "X", "Y", "Z"])
with col3:
    min_zero_weeks = st.slider("–ú—ñ–Ω. —Ç–∏–∂–Ω—ñ–≤ –±–µ–∑ –ø—Ä–æ–¥–∞–∂—ñ–≤", 0, 20, 0)
    search_art = st.text_input("–ü–æ—à—É–∫ –∞—Ä—Ç–∏–∫—É–ª–∞/–Ω–∞–∑–≤–∏")

# –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è —Ñ—ñ–ª—å—Ç—Ä—ñ–≤
filtered_df = final.copy()
if filter_recommendation != "–í—Å—ñ":
    filtered_df = filtered_df[filtered_df['–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è'] == filter_recommendation]
if filter_abc != "–í—Å—ñ":
    filtered_df = filtered_df[filtered_df['abc_category'] == filter_abc]
if filter_xyz != "–í—Å—ñ":
    filtered_df = filtered_df[filtered_df['xyz_category'] == filter_xyz]

filtered_df = filtered_df[
    (filtered_df['prob_dying'] >= min_prob) &
    (filtered_df['consecutive_zeros'] >= min_zero_weeks)
]

if search_art:
    mask = (filtered_df['Art'].astype(str).str.contains(search_art, case=False, na=False) |
            filtered_df['Name'].astype(str).str.contains(search_art, case=False, na=False))
    filtered_df = filtered_df[mask]

# –¢–∞–±–ª–∏—Ü—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
st.subheader(f"üìã –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ ({len(filtered_df)} —Ç–æ–≤–∞—Ä—ñ–≤)")

display_columns = ['Art', 'Name', 'abc_category', 'xyz_category', 'total_qty', 'consecutive_zeros', 'no_store_ratio', 'prob_dying', '–ü—Ä–∏—á–∏–Ω–∞', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è']
if 'forecast_30_median' in filtered_df.columns:
    display_columns.insert(-2, 'forecast_30_median')

display_df = filtered_df[display_columns].copy()
display_df['no_store_ratio'] = (display_df['no_store_ratio'] * 100).round(1)
display_df['prob_dying'] = display_df['prob_dying'].round(1)

column_names = ['–ê—Ä—Ç–∏–∫—É–ª', '–ù–∞–∑–≤–∞', 'ABC', 'XYZ', '–û–±—Å—è–≥', '–¢–∏–∂–Ω—ñ–≤_–±–µ–∑_–ø—Ä–æ–¥–∞–∂—ñ–≤', '–ú–∞–≥–∞–∑–∏–Ω–∏_–±–µ–∑_–ø—Ä–æ–¥–∞–∂—ñ–≤_%', '–ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å_–∑–Ω—è—Ç—Ç—è_%']
if 'forecast_30_median' in display_df.columns:
    column_names.append('–ü—Ä–æ–≥–Ω–æ–∑_30–¥–Ω')
column_names.extend(['–ü—Ä–∏—á–∏–Ω–∞', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è'])

display_df.columns = column_names
st.dataframe(display_df, use_container_width=True)

# === –ï–ö–°–ü–û–†–¢ ===
st.subheader("üíæ –ï–∫—Å–ø–æ—Ä—Ç")
if st.button("üì• –ü—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ Excel"):
    try:
        buffer = BytesIO()
        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
            output_cols = ['Art', 'Name', 'abc_category', 'xyz_category', 'total_qty', 'consecutive_zeros', 'no_store_ratio', 'prob_dying', '–ü—Ä–∏—á–∏–Ω–∞', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è']
            if 'forecast_30_median' in final.columns:
                output_cols.insert(-2, 'forecast_30_median')

            final[output_cols].to_excel(writer, sheet_name='–†–µ–∑—É–ª—å—Ç–∞—Ç–∏', index=False)

            stats = pd.DataFrame({
                '–ú–µ—Ç—Ä–∏–∫–∞': ['–í—Å—å–æ–≥–æ', '–ó–Ω—è—Ç–∏', '–°–ø–æ—Å—Ç–µ—Ä—ñ–≥–∞—Ç–∏', '–ó–∞–ª–∏—à–∏—Ç–∏', '–ü–æ—Ä—ñ–≥_ML_%'],
                '–ó–Ω–∞—á–µ–Ω–Ω—è': [total_products, candidates_remove, candidates_watch,
                           total_products - candidates_remove - candidates_watch, final_threshold*100]
            })
            stats.to_excel(writer, sheet_name='–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', index=False)

            # –ó–≤–µ–¥–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü—è
            summary_pivot.to_excel(writer, sheet_name='–ó–≤–µ–¥–µ–Ω–∞_ABC')

            # –ë—ñ–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫–∏
            metrics_df.to_excel(writer, sheet_name='–ë—ñ–∑–Ω–µ—Å_–º–µ—Ç—Ä–∏–∫–∏', index=False)

            # –¢–æ–ø –¥–æ –∑–Ω—è—Ç—Ç—è
            if len(remove_display) > 0:
                remove_display.to_excel(writer, sheet_name='–¢–æ–ø_–¥–æ_–∑–Ω—è—Ç—Ç—è', index=False)

        st.download_button("üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ Excel", buffer.getvalue(), "analysis_results.xlsx",
                          "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        st.success("‚úÖ –ì–æ—Ç–æ–≤–æ!")
    except Exception as e:
        st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {str(e)}")

with st.expander("‚ÑπÔ∏è –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è"):
    st.write(f"**–°—Ç–∞—Ç—É—Å:** Prophet {'‚úÖ' if PROPHET_AVAILABLE else '‚ùå'}, –û–±—Ä–æ–±–ª–µ–Ω–æ: {len(final)}")
    if not PROPHET_AVAILABLE:
        st.warning("‚ö†Ô∏è –í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å Prophet: pip install prophet")

st.divider()
st.caption("üìä –ó–≤—ñ—Ç –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ —Å–∏—Å—Ç–µ–º–æ—é –∞–Ω–∞–ª—ñ–∑—É —Ç–æ–≤–∞—Ä–Ω–æ–≥–æ –ø–æ—Ä—Ç—Ñ–µ–ª—è")
